/* Copyright (C) 2013-2014, International Business Machines Corporation  */
/* All Rights Reserved                                	                 */

namespace com.ibm.streams.bigdata.hdfs2.helpers ;

/**
 * Convert a tuple to a string and then write to HDFS.
 * The operator converts input tuples on its input stream
 * to strings, and then sends them to the HDFS2FileSink.
 * It includes a default conversion using SPL's tuple
 * format, but allows you to supply a operator
 * to do the conversion from tuple to rstring.
 *  
 * @input inStream Stream to be written to HDFS
 * @param formatter (optional) operator to be used for converting from tuple to string
 * @param writer (optional) operator to be used to write to HDFS
 * @param file File name to be passed on to HDFSFileSink
 * @param timeFormat passed to the file sink; used when the filename contains %TIME
 */
public composite HDFSWriteFormat(input inStream )
{
	param
	// The operator that takes a tuple as input and produces
	// a string.  It defaults to the toText operator, which
	// uses a cast to rstring.
		operator $formatter : com.ibm.streams.bigdata.hdfs2.helpers::toText ;
		// The operator that actually does the writing to HDFS.
		// It defaults to HDFS2FileSink.  If you need to use
		// an option not available in the composite (such as
		// hdfsURI, bytesPerFile, closeOnPunct, or tuplesPerFile)
		// You'll need to supply your own composite.  The 
		// ScanReadWrite sample shows an how to do this.
		operator $writer : com.ibm.streams.bigdata.hdfs2::HDFS2FileSink ;

		// The file to be written.  This is required by the 
		// composite.  
		expression<rstring> $file ;

		// If a user is supplied, the operator uses that value.
		// If no user is supplied, it pulls the user from the 
		// environment variable.  
		expression<rstring> $hdfsUser : getEnvironmentVariable("USER", "") ;

		// If not timeFormat is supplied, the operator uses this
		// value, otherwise it defautls to the same operator default.
		expression<rstring> $timeFormat : "yyyyMMdd_HHmmss" ;
	graph
	// This applies the formatter to the input stream to produce
	// a stream of strings.
		stream<rstring astring> stringStream = $formatter(inStream)
		{
		}

		// Now those strings are written to the sink operator. 
		// The file, hdfsUser, and timeformat parameters are passed through.
		() as Sink = $writer(stringStream)
		{
			param
				file : $file ;
				hdfsUser : $hdfsUser ;
				timeFormat : $timeFormat ;
		}

}

/** Read a line from HDFS and convert it to a tuple.
 *  The operator reads a line from HDFS and converts 
 * it to a tuple.  By default, it use's SPL's cast
 * function to convert from a tuple to a string.
 * @output myStream the output stream of tuples
 * @param file The file on hdfs to be read.
 * @param initDelay (optional) Specifies the time to wait before reading the file.
 * @param hdfsUser (optional) The users to be used when connecting to HDFS.
 * @param decoder (optional) The operator to use to convert a
 * string to a tuple.  By default, it uses the cast
 * function.
 * @param reader (optional) The operator to use to read HDFS lines.
 */
public composite HDFSReadFormat(output myStream )
{
	param
	// The file to be read from HDFS.
		expression<rstring> $file ;
		// The type of the output stream.  This type has to be 
		// passed to the composite.
		type $streamType ;
		// Optionalinitial delay, passed on to the HDFS2FileSource 
		// operator.  Defaults to zero. 
		expression<float64> $initDelay : 0.0 ;
		// Optional user to use to connect to HDFS. 
		// If no user is supplied, it pulls the user from the 
		// environment variable.  
		expression<rstring> $hdfsUser : getEnvironmentVariable("USER", "") ;

		// Optional operator used to take a string and convert it to
		// a tuple; defaults to using SPL's cast function.
		operator $decoder : com.ibm.streams.bigdata.hdfs2.helpers::fromText ;
		// Optional operator used to read from HDFS.  Defaults
		// to HDFS2FileSource.  You would need to overwrite this
		// operator if you need to supply the hdfsURI parameter.
		operator $reader : com.ibm.streams.bigdata.hdfs2::HDFS2FileSource ;
	graph
	// Read the lines from HDFS
		stream<rstring line> lineStream = $reader()
		{
			param
				file : $file ;
				hdfsUser : $hdfsUser ;
				initDelay : $initDelay ;
		}

		// Convert the lines to a tuple type.  This is where the 
		// streamType parameter is used. 
		stream<$streamType> myStream = $decoder(lineStream)
		{
			param
				outType : $streamType ;
		}

}

/** Read from HDFS with filenames supplied on the command line and covert strings to tuples.
 * Treat each tuple on the input stream as a file name, open the file, and
 * convert each line to a tuple.  
 * @input filenames a stream of rstrings representing files in HDFS
 * @output myStream a stream of tuples.  Each tuple corresponds to a line read from HDFS.
 * @param streamType type of the output stream. 
 * @param initDelay optional initial delay before reading files.
 * @param hdfsUser optional parameter specifying user to connect to HDFS
 * @param reader optional parameter to override default operator to use for reading from HDFS.
 * @param decoder optional parameter to overrride default operator to use for converting from HDFS.  It must accept a type parameter.
 */
public composite HDFSReadFormatInputStream(input filenames ; output myStream)
{
	param
	// The operator used to convert from a string to tuple; defaults to operator
	// that uses SPL's cast function.
		operator $decoder : com.ibm.streams.bigdata.hdfs2.helpers::fromText ;
		// Optional operator to use to read from HDFS.  Defaults to HDFS2FileSource.
		// You may need to supply a different composite if you wish to supply the HDFSUri
		// parameter.
		operator $reader : com.ibm.streams.bigdata.hdfs2::HDFS2FileSource ;
		// Optional initial delay. Delay before opening file.
		expression<float64> $initDelay : 0.0 ;
		// The type of the output stream.  (Required.) 
		type $streamType ;
		// Optional user to use to connect to HDFS. 
		// If no user is supplied, it pulls the user from the 
		// environment variable.  
		expression<rstring> $hdfsUser : getEnvironmentVariable("USER", "") ;
	graph

	// Read lines form HDFS, taking filenames from the input stream.
		stream<rstring line> lineStream = $reader(filenames)
		{
			param
				initDelay : $initDelay ;
				hdfsUser : $hdfsUser ;
		}

		// Convert each line to a tuple. 
		stream<$streamType> myStream = $decoder(lineStream)
		{
			param
				outType : $streamType ;
		}

}